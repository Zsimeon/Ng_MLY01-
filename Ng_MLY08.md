#在不同分布上的训练和测试

#36、你什么时候应该在不同的分布上训练和测试

你的猫咪图片应用的使用者已经上传了10000张图片，你已经手动的标记包含有猫咪或者不包含。你也有更大的从网上下载的
200000张图片的数据集。你应该怎么定义训练、开发和测试集？

由于这10000张使用者图片紧密的反映出你实际想在上面表现得好的数据的概率分布，你可以用这个作为你的开发和测试集。
如果你训练一个缺乏数据的深度学习算法，你可以给算法这额外的200000个网络图片来训练。因此，你的训练和开发、测试集
来自于不同的概率分布。这会对你的工作有什么影响呢？

相对于把我们的数据分成训练、开发和测试集，我们能够使用所有的210000张图片，并随机的把他们打乱分成训练、开发和
测试集。在这种情况下，所有的数据来自于相同的分布。但是我反对推荐这种方法，因为你的开发、测试集的
205000/210000≈97.6%都会来自网络图片，并不能反映你想在其上表现得好的实际分布。记住我们的对于选择开发、测试集的
建议：
		选择开发和测试集来反映你期望未来会得到的，并想在其上表现得好的数据

大部分的关于机器学习的学术文献假设训练集、开发集和测试集都来自相同的分布。在机器学习的早期，数据是很缺乏的。
我们通常仅有从一些概率分布中抽出的一个数据集。因此，我们会随机的把这些数据分成训练、开发和测试集，且所有数据
来自于相同的来源的假设通常都是能够满足的。

但是在大数据时代，我们现在有了巨大的训练集，例如猫咪网络图片。即使是训练集相较于开发和测试集来自不同的分布，
我们仍然想要使用它来学习，因为他们提供很多的信息。

对于猫咪检测的例子，相对于把所有的10000个使用者上传的图片放进开发、训练集，我们可能会把5000个放进开发训练集。
我们可以把剩下的5000个使用者上传的图片放进训练集。这样的话，你的205000个例子的训练集包含一些来自你的开发、训练集
分布和200000个网络图片。我们会在后面章节讨论哪种方法会有效。

考虑第二个例子。假设你构建一个语音识别系统来转录一个语音控制的手机地图或航海app的地址。你有20000个使用者说的
街道地址的例子。但是你还有500000个使用者说的其他主题的语音片段例子。你可能会使用10000个街道地址的例子给开发测试集，
使用剩余的10000个加上额外的500000个例子给训练集。

我们会继续假设你的开发集和你的训练集来自相同分布。但是很重要的是要理解不同的训练和开发、测试集分布提供一些特殊的挑战。


# 37、怎么来决定是否使用你的全部数据

假设你的猫咪检测的训练集有10000个使用者上传的图片。这个数据来自相同的分布作为分开的开发、测试集，并表示你关心
想在其上表现得好的分布。你应该提供所有的20000+10000=30000个图片给你的学习算法做为他的训练集，还是分开这20000
个网络图片来害怕他是你的学习算法有偏差？

当使用早期的学习算法时（例如手动设计的计算机视觉特征，和一个简单的线性分类器），把两种数据融合会真的有风险来
导致你的性能变差。因此，一些工程师会警告你别把这20000个网络图片包含在其中。

但是在现代的强力的、灵活的学习算法--例如大型神经网络--这个危险被极大的削减了。如果你的能够负担的其构建一个
有足够大数据的隐藏层和隐藏单元的神经网络，你能安全的添加这20000个图片到你的训练集中。添加这些图片会更可能
提升你的算法性能。

这个观察依赖于一些x映射到y的并对两中类型的数据工作的很好的实例。换句话说，有一些系统能输入网络图片或者
手机app图片并能可靠的预测标签，即使不知道图片的来源。

添加额外的20000个图片有以下的影响：

1. 能给你的神经网络更多的关于猫咪像什么样子或不是什么样子的例子。这很有用，因为网络图片和用户上传的手机app图片
有相同点。你的神经网络能够应用一些从网络图片获得的知识到手机app图片上。

2. 能使神经网络扩展一些功能来学习网络图片的特殊的属性（例如高分辨率，图像怎么构建的不同分布，等等）。如果这些
特性和手机app图片差的很大，它会“耗尽”神经网络的一些表示能力。因此这会使得有很少的能力来识别来自于手机app图像分布，
这是你最关心的。理论上来说，这会伤害你的算法性能。

用不同的术语来描述第二个影响，我们能提到虚构角色夏洛克福尔摩斯，他曾说过你的大脑像一个阁楼；只有有限的空间。
他说“对于每一个额外的知识，在你知道新的知识之前你会忘记一些。这是最重要的，因此，不要让无用的推挤开有用的那些”。

幸运的是，如果你有构建足够大的神经网络的计算能力--例如，一个足够大的阁楼--那么这不是严重的问题。你有足够的能力
从网络和手机app 图片中学习，不管两种类型的数据来竞争能力。你的算法的“大脑”足够大所以你不用担心用光阁楼空间。

但是如果你没有足够大的神经网络（或其他的高灵活性学习算法），那么你应该更加关心你的训练数据来匹配你的开发、
测试集的分布。

如果你认为你有无意义的数据，你应该扔下这些数据来考虑计算力的因素。例如，假设你的开发、测试集包含主要的常规
的人类、场景、地标、动物的图片。假设你有大的扫描的历史文件的收集。

这种文件不包含任何的像猫咪的部分。也看起来完全不想你的开发、测试集分布。毫无必要把这些数据作为负面样例，因为
从上文提到的第一类影响的意义是微不足道的--你的学习算法从这些数据中几乎学不到任何能应用到你的开发、测试集分布
的东西。包含他们会浪费计算资源和神经网络的表示资源。


# 38、怎么决策是否包含前后不一致的数据

假设你想学习预测纽约的房价。给定房屋尺寸（输入特征x），你想要预测价格（目标标签y）。

纽约的房价很贵。假设你有第二个数据集关于底特律、密歇根的房价，那里的房价要低的多。你应该把这些数据加到你的训练集中吗？

给定相同的尺寸x，在底特律或纽约的房价y是很不同的。如果你只关心预测纽约的房价，把这两个数据集仿真一起会伤害你的
性能。这种情况下，扔了不一致的底特律的数据要更好一点。

纽约城和底特律的样例有多少不同于手机app和网络猫咪图片样例呢？

猫咪图片样例是不同的，因为给定输入图片x，能够有效的预测y的标签是否是猫，即使不知道这个图片是网络图片还是手机app图片。
例如，有一个函数f（x）能有效的把输入x映射到目标输出y，即使不知道冤死的x。因此，识别网络图片的任务和识别手机app图片
的任务是“一致的”。这意味着包含所有的数据（相对于计算花费）仅有一点点的负面影响，但有显著的上升。相反，纽约和底特律、
密歇根数据不连贯。给定相同的x（房屋尺寸），价格取决于屋子的位置而大不相同。


# 39、权重数据
假设你有200000个网络图像和5000个手机app用户图像。这些数据集之间有40:1的比例。理论上来说，只要你构建一个巨大的神经网络
并在205000个图片上训练的足够长，那么使算法在网络图像和手机图像上尝试把工作的好是无害的。

但在实际上，有手机app图像40倍的网络图像数据会意味着你需要花费40倍（或者更多的）计算资源来给两者建模，和你只训练5000
个图像相比。

如果你没有大量的计算资源，你可以给网络图片尽可能的低的权重作为妥协。

例如，假设你的最优目标是平方误差（对于分类任务不是一个好的选择，但是会简化我们的解释。）因此，我们的学习算法
尝试来优化：

	min_θ   E_(x,y)属于MobileImg (h_θ(x) - y)^2 + E_(x,y)属于InternetImg(h_θ(x) - y)^2

上面的第一个求和是超过5000个手机图片，第二个求和是超过200000个网络图片。你能最优化一个额外的参数β来代替

	min_θ   E_(x,y)属于MobileImg (h_θ(x) - y)^2 + β * E_(x,y)属于InternetImg(h_θ(x) - y)^2

如果你设置β=1/40，算法会给等同的权重给5000给手机图像和200000个网络图像。你也能够设置β为其他值，可能根据开发集来修改。

通过给额外的网络图片少的权重，你不用构建一个巨大的神经网络来确保算法在两种类型的任务下都运行的很好。这种
重赋权的方法只在你怀疑额外的数据（网络图片）和开发、测试集有一个非常不同的分布的时候才需要，或者如果额外的数据
比来自相同分布的开发、测试集（手机图像）的数量要大得多的时候。