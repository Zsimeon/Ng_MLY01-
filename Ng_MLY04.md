# 23、解决偏差和方差

最简单的解决偏差和方差问题的公式如下：

- 如果你有高可避免偏差，增加你的模型的尺寸（例如，通过添加层或神经元的方法增加你的神经网络的尺寸）。

- 如果你有高方差，给你的训练集添加数据

如果你能无限制的增加神经网络的尺寸和增加训练数据，在很多学习问题中是很可能表现得非常好的。

实际上，增加模型的尺寸会最终导致你走进计算问题，因为训练非常大的模型是很慢的。你可能会耗尽心机来获取更多的训练数据。
（即使是在互联网上，猫咪图片也是有限的）

不同的模型结构-例如，不同的神经网络结构-对你的问题会有不同数量的偏差和方差。很多现今的深度学习研究开发了许多创新的
模型架构。因此如果你使用神经网络，学术文献可以使很好地灵感来源。同样在github上也有很多的开源应用。但是尝试新结构
的结果是比仅仅增加模型尺寸和添加数据要较为不可预测的。

增加模型的尺寸通常减少偏差，但是它也有可能会增加方差和提高过拟合的风险。然而，过拟合问题通常只在你不使用正则化
的时候出现。如果你使用一个很好地设计的正则化方法，那么你通常能够安全的增加模型尺寸而不增加过拟合。

假设你应用深度学习，使用L2正则化或dropout，正则化参数在开发集上性能最好。如果你增加模型的尺寸，通常你的性能会
保持不变或提升；不太可能会显著变差。避免使用一个更大的模型的唯一原因就是增加的计算耗费。


# 24、偏差 vs 方差的权衡

你可能会听过偏差和方差的这种权衡。你可以把变化应用在大多数的学习算法中，可能会减少偏差误差但会增加方差，或者恰恰相反。
这在偏差和方差之间创建了一个“折中”。

例如，增加你的模型的尺寸-在神经网络中添加神经元或神经层，或者添加输入特征-通常减少偏差但会增加方差。反之，
添加正则化通常会增加偏差但会减少方差。

在现代，我们通常有办法获得大量的数据且能够使用非常大的神经网络（深度学习）。因此，这里很少有折中，现在有很多选择
来减少偏差而不伤害方差，或者正相反。

例如，你能够通常增加神经网络尺寸和调整正则化方法来减少偏差而不会明显的增加方差。通过添加训练数据，你也能减少方差而不影响偏差。

如果你选择一个模型架构能很好地适应你的工作，你可能也会同时减少偏差和方差。选择这样一个结构是很难得。

在接下来的一些章节，我们讨论额外的特定技巧来解决偏差和方差。


# 25、减少可避免的偏差的技巧

如果你的学习算法承受很高的可避免偏差，你可以尝试一下技巧：

- *增加模型尺寸*（例如神经元和层的数量）：这个技巧减少偏差，因为它允许你更好的适应训练集。如果你发现这个增加了方差，
那么使用正则化，这通常会消除增加的方差。

- *根据误差分析结果修改输入特征*：假定你的误差分析启发你来创建一个额外的能够帮助算法消除一个确定类的误差的特征。
（我们在下面的章节中进一步讨论这个。）这些新的特征会同时对偏差和方差有帮助。理论上来说，添加更多的特征能够增加方差；
但是如果你这是问题的化，那么使用正则化，这通常会消除方差中的增加值。

- *减少或消除正则化*（L2正则化，L1正则化，dropout）：这能降低可避免偏差，但会曾阿吉方差。

- *修改模型结构*（例如神经网络结构）这是对你的问题更适合的：这个技巧能够影响偏差和方差。

一个没有用的方法：

- *添加更多的训练数据*：这个技巧帮助解决方差问题，但他通常在偏差上没有显著影响。


# 26、训练集上的误差分析

在你期望你的算法能够在开发或测试集上能够表现得好之前，他必须在训练集上表现得很好。

在前面讨论过的解决高偏差的技巧之外，我有时也会在训练集上实验一些误差分析，和在眼球开发集上的误差分析协议相似。
这在你的算法有高偏差的时候是有效的-例如，如果他不能很好地适应训练集。

例如，假设你在对于一个app构造一个语音识别系统并已经从志愿者那里收集了语音片段的训练集。如果你的系统不能在训练集上
表现得好，你可能考虑听100个左右例子组成的集合，这个算法在理解这些例子的主要的训练集误差类别时表现得很差。
和开发集误差分析类似，你能够数在不同类别下的误差;

-------------------------------------------------------------------------------------------------------------------
Audio clip  | Loud background noise | User spoke quickly | Far from microphone |            Comments               |
-------------------------------------------------------------------------------------------------------------------
1           |           √           |                    |                     |            Car noise              |
-------------------------------------------------------------------------------------------------------------------
2           |           √           |                    |         √           |          Restaurant noise         |
-------------------------------------------------------------------------------------------------------------------
3           |                       |          √         |         √           | User shouting across living room？|
-------------------------------------------------------------------------------------------------------------------
4           |           √           |                    |                     |            Coffeeshop             |
-------------------------------------------------------------------------------------------------------------------
% of total  |          75%          |          25%       |         50%         |


在这个例子中，你可能会了解你的算法在有很大的背景噪声的训练样本上有很特别的困难时间。因此，你可以关注那些允许他能更好地
适应有背景噪声的训练样本的技巧。

你也可以再次确认对于一个人来说是否能够转录这些语音片段，给你的学习算法相同的输入语音。如果有很多的背景噪声对于任何人
都不能搞清楚说了什么，那么也不太可能期望一个算法来正确的识别这些发音。我们会在后面的单元讨论你的算法和人类级别性能比较的好处。


# 27、减少方差的技巧

如果你的学习算法忍受高方差，你可以尝试以下技巧：

- *添加更多的训练数据*：这是最简单和最可靠的方法来解决方差，只要你获得有意义的更多数据的方法和足够的计算力来处理数据。

- *增加正则化*（L2正则化，L1正则化，dropout）：这个技巧减少方差但是增加偏差。

- *增加早停*（例如，早点停止梯度下降，基于开发集误差）：这个方法减少方差但是增加偏差。早停止很像正则化方法，
一些作者叫他正则化技巧。

- *特征选择来降低输入特征的数量或类型*：这个几千可能帮助方差问题，但也可能曾阿吉偏差。些微的降低特征数量（从1000到900）
不可能对偏差有很大的影响。显著的减少（从1000到100-10倍的缩减）更有可能有显著的影响，只要你不排除太多的有效的特征。
在现代的深度学习，当数据很大量的时候，可能从特征选择所转移，我们现在更喜欢给算法我们所有的特征，使算法分类基于数据
哪些是要用的。但是当你的训练集很小的时候，特征选择是很有效的。

- *降低模型尺寸*（例如神经元和层的数量）：谨慎使用。这个方法可能降低方差，但可能增加偏差。然而，我不推荐这个方法来解决方差。
添加正则化通常给了更好地分类性能。减小模型尺寸的优势是减少你的计算花费和因此尽可能快的加速你训练模型。如果加速模型训练
是有效的，那么在所有意义上来考虑降低模型尺寸。但是如果你的目标是降低方差，且你不关心计算花费，考虑添加正则化来代替这个方法。

这里有两个额外的策略，重复前面章节的解决偏差：

- *基于误差分析结果来修改输入特征*：你的误差分析启发你来创建一个额外的特征来帮助算法消除特定的误差种类。这些新的特征
能够帮助偏差和方差。理论上来说，添加更多的特征能够增加方差；但是如果你的发现这是一个问题的话，那么使用正则化，会通常
消除增加的方差

- *修改模型架构*（例如神经网络结构）：如果这是更适合你的问题的：这个方法能够影响偏差和方差。